{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ef606d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ec280d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1048575\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ner_d.csv', encoding = \"ISO-8859-1\")\n",
    "print(len(df))\n",
    "# df = df[:100000]\n",
    "#50000 and above, 80000,100000\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cf369299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47959, 35177, 17)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.fillna(method='ffill')\n",
    "df['Sentence #'].nunique(), df.Word.nunique(), df.Tag.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6c8e2274",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-art</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-eve</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-geo</td>\n",
       "      <td>37644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B-gpe</td>\n",
       "      <td>15870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B-nat</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B-org</td>\n",
       "      <td>20143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B-per</td>\n",
       "      <td>16990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B-tim</td>\n",
       "      <td>20333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I-art</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I-eve</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I-geo</td>\n",
       "      <td>7414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I-gpe</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I-nat</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I-org</td>\n",
       "      <td>16784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I-per</td>\n",
       "      <td>17251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I-tim</td>\n",
       "      <td>6528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>O</td>\n",
       "      <td>887908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tag  counts\n",
       "0   B-art     402\n",
       "1   B-eve     308\n",
       "2   B-geo   37644\n",
       "3   B-gpe   15870\n",
       "4   B-nat     201\n",
       "5   B-org   20143\n",
       "6   B-per   16990\n",
       "7   B-tim   20333\n",
       "8   I-art     297\n",
       "9   I-eve     253\n",
       "10  I-geo    7414\n",
       "11  I-gpe     198\n",
       "12  I-nat      51\n",
       "13  I-org   16784\n",
       "14  I-per   17251\n",
       "15  I-tim    6528\n",
       "16      O  887908"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Tag').size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d70b4fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cc2cb9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func_x = lambda s: [w for w in s['Word'].values.tolist()]\n",
    "        agg_func_y = lambda s: [[p, t] for p, t in zip(s['POS'].values.tolist(),s['Tag'].values.tolist())]\n",
    "        \n",
    "        self.grouped_x = self.data.groupby('Sentence #').apply(agg_func_x)\n",
    "        self.grouped_y = self.data.groupby('Sentence #').apply(agg_func_y)\n",
    "        self.x=[s for s in self.grouped_x]\n",
    "        self.y=[s for s in self.grouped_y]\n",
    "        \n",
    "#     def get_next(self):\n",
    "#         try: \n",
    "#             s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
    "#             self.n_sent += 1\n",
    "#             return s \n",
    "#         except:\n",
    "#             return None\n",
    "getter = SentenceGetter(df)\n",
    "sentence_x = getter.x\n",
    "sentence_y=getter.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "922c7768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iranian', 'officials', 'say', 'they', 'expect', 'to', 'get', 'access', 'to', 'sealed', 'sensitive', 'parts', 'of', 'the', 'plant', 'Wednesday', ',', 'after', 'an', 'IAEA', 'surveillance', 'system', 'begins', 'functioning', '.']\n",
      "[['JJ', 'B-gpe'], ['NNS', 'O'], ['VBP', 'O'], ['PRP', 'O'], ['VBP', 'O'], ['TO', 'O'], ['VB', 'O'], ['NN', 'O'], ['TO', 'O'], ['JJ', 'O'], ['JJ', 'O'], ['NNS', 'O'], ['IN', 'O'], ['DT', 'O'], ['NN', 'O'], ['NNP', 'B-tim'], [',', 'O'], ['IN', 'O'], ['DT', 'O'], ['NNP', 'B-org'], ['NN', 'O'], ['NN', 'O'], ['VBZ', 'O'], ['VBG', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(sentence_x[1])\n",
    "print(sentence_y[1])\n",
    "assert len(sentence_x[1])==len(sentence_y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "78000b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################################\n",
    "\n",
    "def word2features(sent, i):\n",
    "    word = sent[i]\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0, \n",
    "        'word.lower()': word.lower(), \n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit()\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper()\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "    \n",
    "    \n",
    "    #extract features from 2 last words\n",
    "    if i > 1:\n",
    "        word1 = sent[i-2][0]\n",
    "        features.update({\n",
    "            '-2:word.lower()': word1.lower(),\n",
    "            '-2:word.istitle()': word1.istitle(),\n",
    "            '-2:word.isupper()': word1.isupper()\n",
    "        }) \n",
    "        \n",
    "        \n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper()\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "    \n",
    "    \n",
    "    #extract features from 2 next words\n",
    "    if i < len(sent)-2:\n",
    "        word1 = sent[i+2][0]\n",
    "        features.update({\n",
    "            '+2:word.lower()': word1.lower(),\n",
    "            '+2:word.istitle()': word1.istitle(),\n",
    "            '+2:word.isupper()': word1.isupper()\n",
    "        })\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    features['position']=np.sin(i)\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent_x):\n",
    "    return [word2features(sent_x, i) for i in range(len(sent_x))]\n",
    "def sent2labels(sent_y):\n",
    "    return [label for postag, label in sent_y]\n",
    "def sent2postag(sent_y):\n",
    "    return [postag for postag, label in sent_y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e9446f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in sentence_x]\n",
    "y1 = [sent2labels(s) for s in sentence_y]\n",
    "y2 = [sent2postag(s) for s in sentence_y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ea272651",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(y2[0])==len(y1[0])==len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "09b549a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_length=int(len(X)*0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0600bba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_set=X[0:train_length]\n",
    "y1_train_set=y1[0:train_length]\n",
    "y2_train_set=y2[0:train_length]\n",
    "\n",
    "x_test_set=X[train_length:]\n",
    "y1_test_set=y1[train_length:]\n",
    "y2_test_set=y2[train_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "610b30dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=300,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "try:\n",
    "    crf.fit(x_train_set, y1_train_set)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a0fd5991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33033\n",
      "41420\n",
      "0.7975132786093675\n"
     ]
    }
   ],
   "source": [
    "y_pred = crf.predict(x_test_set)\n",
    "\n",
    "#calculate accuracy\n",
    "t_pred=[]\n",
    "t_test=[]\n",
    "for x in y_pred:\n",
    "    t_pred.extend(x)\n",
    "    \n",
    "for x in y1_test_set:\n",
    "    t_test.extend(x)\n",
    "\n",
    "n_test=[]\n",
    "n_pred=[]\n",
    "for i in range(len(t_pred)):\n",
    "    if t_pred[i]==t_test[i] and t_pred[i]=='O':\n",
    "        pass\n",
    "    else:\n",
    "        n_test.append(t_test[i])\n",
    "        n_pred.append(t_pred[i])\n",
    "\n",
    "#print(f1_score(t_pred, t_test, average=\"micro\"))\n",
    "n_pred=np.array(n_pred)\n",
    "n_test=np.array(n_test)\n",
    "right=len(n_test[n_pred==n_test])\n",
    "alles=len(n_test)\n",
    "print(right)\n",
    "print(alles)\n",
    "print(right/alles)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d0c661",
   "metadata": {},
   "source": [
    "# Bewerbung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "85584c38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "B-art  -> I-art   7.828138\n",
      "I-eve  -> I-eve   6.996550\n",
      "B-nat  -> I-nat   6.948121\n",
      "B-geo  -> I-geo   6.916702\n",
      "I-art  -> I-art   6.484916\n",
      "B-eve  -> I-eve   6.374049\n",
      "B-per  -> I-per   6.130867\n",
      "I-tim  -> I-tim   5.979728\n",
      "I-gpe  -> I-gpe   5.826919\n",
      "B-tim  -> I-tim   5.746286\n",
      "I-geo  -> I-geo   5.630867\n",
      "B-org  -> I-org   5.592338\n",
      "I-org  -> I-org   5.510719\n",
      "B-gpe  -> I-gpe   5.144799\n",
      "I-per  -> I-per   4.951164\n",
      "I-nat  -> I-nat   3.601268\n",
      "O      -> O       2.609024\n",
      "B-geo  -> B-tim   2.048582\n",
      "O      -> B-eve   1.845022\n",
      "O      -> B-per   1.843359\n",
      "\n",
      "Top unlikely transitions:\n",
      "I-per  -> B-geo   -3.448911\n",
      "B-tim  -> I-org   -3.524673\n",
      "I-org  -> I-geo   -3.599099\n",
      "B-geo  -> I-org   -3.607279\n",
      "I-org  -> I-per   -3.723078\n",
      "I-org  -> I-tim   -3.814219\n",
      "B-org  -> B-org   -3.920244\n",
      "B-tim  -> B-tim   -4.090297\n",
      "O      -> I-eve   -4.132584\n",
      "B-gpe  -> I-geo   -4.264852\n",
      "I-org  -> B-org   -4.396174\n",
      "O      -> I-art   -4.555218\n",
      "B-gpe  -> I-org   -4.695370\n",
      "O      -> I-per   -5.149958\n",
      "B-gpe  -> B-gpe   -5.337813\n",
      "I-per  -> B-per   -5.480365\n",
      "B-per  -> B-per   -5.983198\n",
      "O      -> I-org   -6.821997\n",
      "O      -> I-tim   -6.886067\n",
      "O      -> I-geo   -7.205349\n"
     ]
    }
   ],
   "source": [
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(20))\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common()[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "65a01da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# save\n",
    "joblib.dump(crf, \"model_crf.pkl\") \n",
    "\n",
    "# load\n",
    "crf2 = joblib.load(\"model_crf.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264c37da",
   "metadata": {},
   "source": [
    "# question test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d3ef270c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Who', 'is', 'the', 'screenwriter', 'of', 'The', 'Masked', 'Gang:', 'Cyprus?']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['O', 'O', 'O', 'O', 'O', 'B-org', 'I-org', 'I-org', 'I-org']]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question=\"Who is the screenwriter of The Masked Gang: Cyprus?\"\n",
    "question=question.split(' ')\n",
    "print(question)\n",
    "q_x=[sent2features(question)]\n",
    "q_y = crf2.predict(q_x)\n",
    "q_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ed0a85",
   "metadata": {},
   "source": [
    "# try more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fa227711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a642ba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bd417739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050795\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lemma</th>\n",
       "      <th>next-lemma</th>\n",
       "      <th>next-next-lemma</th>\n",
       "      <th>next-next-pos</th>\n",
       "      <th>next-next-shape</th>\n",
       "      <th>next-next-word</th>\n",
       "      <th>next-pos</th>\n",
       "      <th>next-shape</th>\n",
       "      <th>next-word</th>\n",
       "      <th>pos</th>\n",
       "      <th>prev-iob</th>\n",
       "      <th>prev-lemma</th>\n",
       "      <th>prev-pos</th>\n",
       "      <th>prev-prev-iob</th>\n",
       "      <th>prev-prev-lemma</th>\n",
       "      <th>prev-prev-pos</th>\n",
       "      <th>prev-prev-shape</th>\n",
       "      <th>prev-prev-word</th>\n",
       "      <th>prev-shape</th>\n",
       "      <th>prev-word</th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>shape</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>thousand</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>NNS</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>__start1__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>__start2__</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>1.0</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>thousand</td>\n",
       "      <td>NNS</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>__start1__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>have</td>\n",
       "      <td>march</td>\n",
       "      <td>VBN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBP</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>thousand</td>\n",
       "      <td>NNS</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>have</td>\n",
       "      <td>march</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>through</td>\n",
       "      <td>VBN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>march</td>\n",
       "      <td>through</td>\n",
       "      <td>london</td>\n",
       "      <td>NNP</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>London</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>through</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     lemma next-lemma next-next-lemma next-next-pos  \\\n",
       "0           0  thousand         of        demonstr           NNS   \n",
       "1           1        of   demonstr            have           VBP   \n",
       "2           2  demonstr       have           march           VBN   \n",
       "3           3      have      march         through            IN   \n",
       "4           4     march    through          london           NNP   \n",
       "\n",
       "  next-next-shape next-next-word next-pos next-shape      next-word  pos  \\\n",
       "0       lowercase  demonstrators       IN  lowercase             of  NNS   \n",
       "1       lowercase           have      NNS  lowercase  demonstrators   IN   \n",
       "2       lowercase        marched      VBP  lowercase           have  NNS   \n",
       "3       lowercase        through      VBN  lowercase        marched  VBP   \n",
       "4     capitalized         London       IN  lowercase        through  VBN   \n",
       "\n",
       "     prev-iob  prev-lemma    prev-pos prev-prev-iob prev-prev-lemma  \\\n",
       "0  __START1__  __start1__  __START1__    __START2__      __start2__   \n",
       "1           O    thousand         NNS    __START1__      __start1__   \n",
       "2           O          of          IN             O        thousand   \n",
       "3           O    demonstr         NNS             O              of   \n",
       "4           O        have         VBP             O        demonstr   \n",
       "\n",
       "  prev-prev-pos prev-prev-shape prev-prev-word   prev-shape      prev-word  \\\n",
       "0    __START2__        wildcard     __START2__     wildcard     __START1__   \n",
       "1    __START1__        wildcard     __START1__  capitalized      Thousands   \n",
       "2           NNS     capitalized      Thousands    lowercase             of   \n",
       "3            IN       lowercase             of    lowercase  demonstrators   \n",
       "4           NNS       lowercase  demonstrators    lowercase           have   \n",
       "\n",
       "   sentence_idx        shape           word tag  \n",
       "0           1.0  capitalized      Thousands   O  \n",
       "1           1.0    lowercase             of   O  \n",
       "2           1.0    lowercase  demonstrators   O  \n",
       "3           1.0    lowercase           have   O  \n",
       "4           1.0    lowercase        marched   O  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_df = pd.read_csv('ner.csv',encoding='cp1252')\n",
    "# n_df = pd.read_csv('ner.csv', encoding = \"ISO-8859-1\")\n",
    "print(len(n_df))\n",
    "# df = df[:100000]\n",
    "#50000 and above, 80000,100000\n",
    "n_df.head()\n",
    "\n",
    "#DELETE LINE 281837 BUGS HERE!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1062bff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func_x = lambda s: [w for w in s['word'].values.tolist()]\n",
    "        agg_func_y = lambda s: [[p, t] for p, t in zip(s['pos'].values.tolist(),s['tag'].values.tolist())]\n",
    "        \n",
    "        self.grouped_x = self.data.groupby('sentence_idx').apply(agg_func_x)\n",
    "        self.grouped_y = self.data.groupby('sentence_idx').apply(agg_func_y)\n",
    "        self.x=[s for s in self.grouped_x]\n",
    "        self.y=[s for s in self.grouped_y]\n",
    "        \n",
    "#     def get_next(self):\n",
    "#         try: \n",
    "#             s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
    "#             self.n_sent += 1\n",
    "#             return s \n",
    "#         except:\n",
    "#             return None\n",
    "getter = SentenceGetter(n_df)\n",
    "big_sentence_x = getter.x\n",
    "big_sentence_y=getter.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "15e3a552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = str(sent[i])\n",
    "    features = {\n",
    "        'bias': 1.0, \n",
    "        'word.lower()': word.lower(), \n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit()\n",
    "    }\n",
    "    \n",
    "\n",
    "    if i > 0:\n",
    "        word1 = str(sent[i-1])[0]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper()\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "        \n",
    "    if i > 1:\n",
    "        word1 = str(sent[i-2])[0]\n",
    "        features.update({\n",
    "            '-2:word.lower()': word1.lower(),\n",
    "            '-2:word.istitle()': word1.istitle(),\n",
    "            '-2:word.isupper()': word1.isupper()\n",
    "        }) \n",
    "        \n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = str(sent[i+1])[0]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper()\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "        \n",
    "        \n",
    "    \n",
    "    #extract features from 2 next words\n",
    "    if i < len(sent)-2:\n",
    "        word1 = str(sent[i+2])[0]\n",
    "        features.update({\n",
    "            '+2:word.lower()': word1.lower(),\n",
    "            '+2:word.istitle()': word1.istitle(),\n",
    "            '+2:word.isupper()': word1.isupper()\n",
    "        })\n",
    "    \n",
    "\n",
    "\n",
    "    features['position']=np.sin(i)\n",
    "    return features\n",
    "\n",
    "def sent2features(sent_x):\n",
    "    return [word2features(sent_x, i) for i in range(len(sent_x))]\n",
    "def sent2labels(sent_y):\n",
    "    return [label for postag, label in sent_y]\n",
    "def sent2postag(sent_y):\n",
    "    return [postag for postag, label in sent_y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "378f5cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in big_sentence_x]\n",
    "y1 = [sent2labels(s) for s in big_sentence_y]\n",
    "y2 = [sent2postag(s) for s in big_sentence_y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b4cf10fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_length=int(len(X)*0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e54955c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_set=X[0:train_length]\n",
    "y1_train_set=y1[0:train_length]\n",
    "y2_train_set=y2[0:train_length]\n",
    "\n",
    "x_test_set=X[train_length:]\n",
    "y1_test_set=y1[train_length:]\n",
    "y2_test_set=y2[train_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f41d94cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=300,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "try:\n",
    "    crf.fit(x_train_set, y1_train_set)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cdfb2d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24094\n",
      "30525\n",
      "0.7893202293202293\n"
     ]
    }
   ],
   "source": [
    "y_pred = crf.predict(x_test_set)\n",
    "\n",
    "#calculate accuracy\n",
    "t_pred=[]\n",
    "t_test=[]\n",
    "for x in y_pred:\n",
    "    t_pred.extend(x)\n",
    "    \n",
    "for x in y1_test_set:\n",
    "    t_test.extend(x)\n",
    "\n",
    "n_test=[]\n",
    "n_pred=[]\n",
    "for i in range(len(t_pred)):\n",
    "    if t_pred[i]==t_test[i] and t_pred[i]=='O':\n",
    "        pass\n",
    "    else:\n",
    "        n_test.append(t_test[i])\n",
    "        n_pred.append(t_pred[i])\n",
    "\n",
    "#print(f1_score(t_pred, t_test, average=\"micro\"))\n",
    "n_pred=np.array(n_pred)\n",
    "n_test=np.array(n_test)\n",
    "right=len(n_test[n_pred==n_test])\n",
    "alles=len(n_test)\n",
    "print(right)\n",
    "print(alles)\n",
    "print(right/alles)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d36b8352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# save\n",
    "joblib.dump(crf, \"model_crf.pkl\") \n",
    "\n",
    "# load\n",
    "crf = joblib.load(\"model_crf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4319775e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Who', 'is', 'the', 'screenwriter', 'of', 'The', 'Masked', 'Gang:', 'Cyprus?']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['O', 'O', 'O', 'O', 'O', 'B-org', 'I-org', 'I-org', 'I-org']]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question=\"Who is the screenwriter of The Masked Gang: Cyprus?\"\n",
    "question=question.split(' ')\n",
    "print(question)\n",
    "q_x=[sent2features(question)]\n",
    "q_y = crf2.predict(q_x)\n",
    "q_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cd6edd",
   "metadata": {},
   "source": [
    "# with pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f7c527a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "105c8f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f7493436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050795\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lemma</th>\n",
       "      <th>next-lemma</th>\n",
       "      <th>next-next-lemma</th>\n",
       "      <th>next-next-pos</th>\n",
       "      <th>next-next-shape</th>\n",
       "      <th>next-next-word</th>\n",
       "      <th>next-pos</th>\n",
       "      <th>next-shape</th>\n",
       "      <th>next-word</th>\n",
       "      <th>pos</th>\n",
       "      <th>prev-iob</th>\n",
       "      <th>prev-lemma</th>\n",
       "      <th>prev-pos</th>\n",
       "      <th>prev-prev-iob</th>\n",
       "      <th>prev-prev-lemma</th>\n",
       "      <th>prev-prev-pos</th>\n",
       "      <th>prev-prev-shape</th>\n",
       "      <th>prev-prev-word</th>\n",
       "      <th>prev-shape</th>\n",
       "      <th>prev-word</th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>shape</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>thousand</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>NNS</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>__start1__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>__start2__</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>1.0</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>thousand</td>\n",
       "      <td>NNS</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>__start1__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>have</td>\n",
       "      <td>march</td>\n",
       "      <td>VBN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBP</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>thousand</td>\n",
       "      <td>NNS</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>have</td>\n",
       "      <td>march</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>through</td>\n",
       "      <td>VBN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>march</td>\n",
       "      <td>through</td>\n",
       "      <td>london</td>\n",
       "      <td>NNP</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>London</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>through</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     lemma next-lemma next-next-lemma next-next-pos  \\\n",
       "0           0  thousand         of        demonstr           NNS   \n",
       "1           1        of   demonstr            have           VBP   \n",
       "2           2  demonstr       have           march           VBN   \n",
       "3           3      have      march         through            IN   \n",
       "4           4     march    through          london           NNP   \n",
       "\n",
       "  next-next-shape next-next-word next-pos next-shape      next-word  pos  \\\n",
       "0       lowercase  demonstrators       IN  lowercase             of  NNS   \n",
       "1       lowercase           have      NNS  lowercase  demonstrators   IN   \n",
       "2       lowercase        marched      VBP  lowercase           have  NNS   \n",
       "3       lowercase        through      VBN  lowercase        marched  VBP   \n",
       "4     capitalized         London       IN  lowercase        through  VBN   \n",
       "\n",
       "     prev-iob  prev-lemma    prev-pos prev-prev-iob prev-prev-lemma  \\\n",
       "0  __START1__  __start1__  __START1__    __START2__      __start2__   \n",
       "1           O    thousand         NNS    __START1__      __start1__   \n",
       "2           O          of          IN             O        thousand   \n",
       "3           O    demonstr         NNS             O              of   \n",
       "4           O        have         VBP             O        demonstr   \n",
       "\n",
       "  prev-prev-pos prev-prev-shape prev-prev-word   prev-shape      prev-word  \\\n",
       "0    __START2__        wildcard     __START2__     wildcard     __START1__   \n",
       "1    __START1__        wildcard     __START1__  capitalized      Thousands   \n",
       "2           NNS     capitalized      Thousands    lowercase             of   \n",
       "3            IN       lowercase             of    lowercase  demonstrators   \n",
       "4           NNS       lowercase  demonstrators    lowercase           have   \n",
       "\n",
       "   sentence_idx        shape           word tag  \n",
       "0           1.0  capitalized      Thousands   O  \n",
       "1           1.0    lowercase             of   O  \n",
       "2           1.0    lowercase  demonstrators   O  \n",
       "3           1.0    lowercase           have   O  \n",
       "4           1.0    lowercase        marched   O  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_df = pd.read_csv('ner.csv',encoding='cp1252')\n",
    "# n_df = pd.read_csv('ner.csv', encoding = \"ISO-8859-1\")\n",
    "print(len(n_df))\n",
    "# df = df[:100000]\n",
    "#50000 and above, 80000,100000\n",
    "n_df.head()\n",
    "\n",
    "#DELETE LINE 281837 BUGS HERE!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "73c6c005",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func_x = lambda s: [[w,p] for w,p in zip(s['word'].values.tolist(),s['pos'].values.tolist())]\n",
    "        agg_func_y = lambda s: [t for t in s['tag'].values.tolist()]\n",
    "        \n",
    "        self.grouped_x = self.data.groupby('sentence_idx').apply(agg_func_x)\n",
    "        self.grouped_y = self.data.groupby('sentence_idx').apply(agg_func_y)\n",
    "        self.x=[s for s in self.grouped_x]\n",
    "        self.y=[s for s in self.grouped_y]\n",
    "        \n",
    "#     def get_next(self):\n",
    "#         try: \n",
    "#             s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
    "#             self.n_sent += 1\n",
    "#             return s \n",
    "#         except:\n",
    "#             return None\n",
    "getter = SentenceGetter(n_df)\n",
    "big_sentence_x = getter.x\n",
    "big_sentence_y=getter.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "aed30bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = str(sent[i][0])\n",
    "    tag=str(sent[i][1])\n",
    "    features = {\n",
    "        'bias': 1.0, \n",
    "        'word.lower()': word.lower(), \n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'word.tag':tag\n",
    "    }\n",
    "    \n",
    "\n",
    "    if i > 0:\n",
    "        word1 = str(sent[i-1][0])\n",
    "        tag1=str(sent[i-1][1])\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:word.tag':tag1\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "        \n",
    "    if i > 1:\n",
    "        word1 = str(sent[i-2][0])\n",
    "        tag1 = str(sent[i-2][1])\n",
    "        features.update({\n",
    "            '-2:word.lower()': word1.lower(),\n",
    "            '-2:word.istitle()': word1.istitle(),\n",
    "            '-2:word.isupper()': word1.isupper(),\n",
    "            '-2:word.tag':tag1\n",
    "        }) \n",
    "        \n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = str(sent[i+1][0])\n",
    "        tag1 = str(sent[i+1][1])\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:word.tag':tag1\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "        \n",
    "        \n",
    "    \n",
    "    #extract features from 2 next words\n",
    "    if i < len(sent)-2:\n",
    "        word1 = str(sent[i+2][0])\n",
    "        tag1 = str(sent[i+2][1])\n",
    "        features.update({\n",
    "            '+2:word.lower()': word1.lower(),\n",
    "            '+2:word.istitle()': word1.istitle(),\n",
    "            '+2:word.isupper()': word1.isupper(),\n",
    "            '+2:word.tag': tag1\n",
    "        })\n",
    "    \n",
    "\n",
    "\n",
    "    features['position']=np.sin(i)\n",
    "    return features\n",
    "\n",
    "def sent2features(sent_x):\n",
    "    return [word2features(sent_x, i) for i in range(len(sent_x))]\n",
    "def sent2labels(sent_y):\n",
    "    return [label for label in sent_y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ebb6cf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in big_sentence_x]\n",
    "y = [sent2labels(s) for s in big_sentence_y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "445ff8b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_length=int(len(X)*0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "632ca9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_set=X[0:train_length]\n",
    "y_train_set=y[0:train_length]\n",
    "\n",
    "x_test_set=X[train_length:]\n",
    "y_test_set=y[train_length:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a4549eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=300,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "try:\n",
    "    crf.fit(x_train_set, y_train_set)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "61e63dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24619\n",
      "30366\n",
      "0.8107422775472568\n"
     ]
    }
   ],
   "source": [
    "y_pred = crf.predict(x_test_set)\n",
    "\n",
    "#calculate accuracy\n",
    "t_pred=[]\n",
    "t_test=[]\n",
    "for x in y_pred:\n",
    "    t_pred.extend(x)\n",
    "    \n",
    "for x in y_test_set:\n",
    "    t_test.extend(x)\n",
    "\n",
    "n_test=[]\n",
    "n_pred=[]\n",
    "for i in range(len(t_pred)):\n",
    "    if t_pred[i]==t_test[i] and t_pred[i]=='O':\n",
    "        pass\n",
    "    else:\n",
    "        n_test.append(t_test[i])\n",
    "        n_pred.append(t_pred[i])\n",
    "\n",
    "#print(f1_score(t_pred, t_test, average=\"micro\"))\n",
    "n_pred=np.array(n_pred)\n",
    "n_test=np.array(n_test)\n",
    "right=len(n_test[n_pred==n_test])\n",
    "alles=len(n_test)\n",
    "print(right)\n",
    "print(alles)\n",
    "print(right/alles)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "66235e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# save\n",
    "joblib.dump(crf, \"model_crf.pkl\") \n",
    "\n",
    "# load\n",
    "crf2 = joblib.load(\"model_crf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f5aa2bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Who', 'is', 'the', 'screenwriter', 'of', 'The', 'Masked', 'Gang:', 'Cyprus?']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['O', 'O', 'O', 'O', 'O', 'B-art', 'I-art', 'I-art', 'I-art']]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question=\"Who is the screenwriter of The Masked Gang: Cyprus?\"\n",
    "question=question.split(' ')\n",
    "print(question)\n",
    "q_x=[sent2features(question)]\n",
    "q_y = crf2.predict(q_x)\n",
    "q_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5170d1",
   "metadata": {},
   "source": [
    "# check repeating sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04c20360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1fa78f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ner_d.csv', encoding = \"ISO-8859-1\")\n",
    "df = df.fillna(method='ffill')\n",
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func_x = lambda s: [w for w in s['Word'].values.tolist()]\n",
    "        agg_func_y = lambda s: [[p, t] for p, t in zip(s['POS'].values.tolist(),s['Tag'].values.tolist())]\n",
    "        \n",
    "        self.grouped_x = self.data.groupby('Sentence #').apply(agg_func_x)\n",
    "        self.grouped_y = self.data.groupby('Sentence #').apply(agg_func_y)\n",
    "        self.x=[s for s in self.grouped_x]\n",
    "        self.y=[s for s in self.grouped_y]\n",
    "\n",
    "getter = SentenceGetter(df)\n",
    "sentence_x = getter.x\n",
    "sentence_y=getter.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8fcf01c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_df = pd.read_csv('ner.csv',encoding='cp1252')\n",
    "n_df.head()\n",
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func_x = lambda s: [w for w in s['word'].values.tolist()]\n",
    "        agg_func_y = lambda s: [[p, t] for p, t in zip(s['pos'].values.tolist(),s['tag'].values.tolist())]\n",
    "        \n",
    "        self.grouped_x = self.data.groupby('sentence_idx').apply(agg_func_x)\n",
    "        self.grouped_y = self.data.groupby('sentence_idx').apply(agg_func_y)\n",
    "        self.x=[s for s in self.grouped_x]\n",
    "        self.y=[s for s in self.grouped_y]\n",
    "        \n",
    "getter = SentenceGetter(n_df)\n",
    "big_sentence_x = getter.x\n",
    "big_sentence_y=getter.y\n",
    "#DELETE LINE 281837 BUGS HERE!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e5f12036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat=0\n",
    "# for i in range(len(sentence_x)):\n",
    "#     for j in range(len(big_sentence_x)):\n",
    "#         if sentence_x[i]==big_sentence_x[j]:\n",
    "#             print(sentence_x[i])\n",
    "#             repeat+=1\n",
    "# print(repeat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0df3649c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47959\n",
      "35177\n"
     ]
    }
   ],
   "source": [
    "print(len(sentence_x))\n",
    "print(len(big_sentence_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84b3c18",
   "metadata": {},
   "source": [
    "# fix this bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5467af91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_repeated_sentence(sentence,sentence_list,y_sentence_list):\n",
    "    for i in range(len(sentence_list)):\n",
    "        if sentence_list[i]==sentence:\n",
    "            del sentence_list[i],y_sentence_list[i]\n",
    "            break\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d3addccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47959\n",
      "12924\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sentence_x)):\n",
    "    delete_repeated_sentence(sentence_x[i],big_sentence_x,big_sentence_y)\n",
    "    \n",
    "for i in range(len(big_sentence_x)):\n",
    "    delete_repeated_sentence(big_sentence_x[i],sentence_x,sentence_y)\n",
    "\n",
    "    \n",
    "print(len(sentence_x))\n",
    "print(len(big_sentence_x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
