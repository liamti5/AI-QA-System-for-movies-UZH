{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import sys\n",
    "sys.path.append(\"../models/\")\n",
    "import NER_CRF\n",
    "\n",
    "\n",
    "class NLP_Operations:\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    def get_ner(self, question):\n",
    "        ner = NER_CRF.get_ner(question)\n",
    "        return ner\n",
    "\n",
    "    def get_relation(self, question):\n",
    "        doc = self.nlp(question)\n",
    "        relations = [\n",
    "            tok.lemma_\n",
    "            for tok in doc\n",
    "            if tok.dep_ in (\"attr\", \"nsubj\") and tok.pos_ in (\"NOUN\")\n",
    "        ]\n",
    "        return relations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def get_dicti(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        dicti = json.load(f)\n",
    "    return dicti\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdflib\n",
    "\n",
    "\n",
    "class GraphOperations:\n",
    "    def __init__(self, graph_file=\"data/14_graph.nt\"):\n",
    "        self.graph = rdflib.Graph()\n",
    "        # self.load_graph(graph_file)\n",
    "\n",
    "    def load_graph(self, graph_file):\n",
    "        print(\"loading graph ...\")\n",
    "        self.graph.parse(graph_file, format=\"turtle\")\n",
    "        print(\"loaded graph successfully!\")\n",
    "\n",
    "    def query(self, message):\n",
    "        # remember to delete these 2 lines after this boring evaluation\n",
    "        message = message.replace('\"\"\"', \"\").replace(\"'''\", \"\")\n",
    "        print(\"message in sparql\")\n",
    "        message = str(message)\n",
    "        print(message)\n",
    "        temp = [str(s) for s, in self.graph.query(message)]\n",
    "        print(temp)\n",
    "        return temp\n",
    "\n",
    "    def query2(self, message):\n",
    "        return calculate_answer(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.append(\"../usecases/\")\n",
    "# import utils\n",
    "# import nlp_operations\n",
    "# import graph_operations\n",
    "import copy\n",
    "import editdistance\n",
    "\n",
    "\n",
    "class AnswerCalculator:\n",
    "    def __init__(self):\n",
    "        self.nodes = get_dicti(\"../data/nodes.json\")\n",
    "        self.predicates = get_dicti(\"../data/predicates_clean.json\")\n",
    "        self.nlp_operator = NLP_Operations()\n",
    "        self.graph_operator = GraphOperations()\n",
    "        self.wh_words = [\n",
    "            \"What\",\n",
    "            \"what\",\n",
    "            \"when\",\n",
    "            \"When\",\n",
    "            \"where\",\n",
    "            \"Where\",\n",
    "            \"Who\",\n",
    "            \"who\",\n",
    "            \"Whom\",\n",
    "            \"whom\",\n",
    "            \"Which\",\n",
    "            \"which\",\n",
    "            \"Whose\",\n",
    "            \"whose\",\n",
    "            \"Why\",\n",
    "            \"why\",\n",
    "            \"How\",\n",
    "            \"how\",\n",
    "        ]\n",
    "        self.useless_words = [\n",
    "            \"am\",\n",
    "            \"is\",\n",
    "            \"are\",\n",
    "            \"was\",\n",
    "            \"were\",\n",
    "            \"a\",\n",
    "            \"an\",\n",
    "            \"the\",\n",
    "            \"that\",\n",
    "            \"this\",\n",
    "            \"these\",\n",
    "            \"those\",\n",
    "            \"above\",\n",
    "            \"across\",\n",
    "            \"against\",\n",
    "            \"along\",\n",
    "            \"among\",\n",
    "            \"around\",\n",
    "            \"at\",\n",
    "            \"before\",\n",
    "            \"behind\",\n",
    "            \"below\",\n",
    "            \"beneath\",\n",
    "            \"beside\",\n",
    "            \"between\",\n",
    "            \"by\",\n",
    "            \"down\",\n",
    "            \"from\",\n",
    "            \"in\",\n",
    "            \"into\",\n",
    "            \"near\",\n",
    "            \"off\",\n",
    "            \"on\",\n",
    "            \"to\",\n",
    "            \"woward\",\n",
    "            \"under\",\n",
    "            \"upon\",\n",
    "            \"with\",\n",
    "            \"and\",\n",
    "            \"within\",\n",
    "            \"of\",\n",
    "            \"for\",\n",
    "            \"since\",\n",
    "            \"during\",\n",
    "            \"over\",\n",
    "        ]\n",
    "        self.all_delete_words = self.wh_words + self.useless_words\n",
    "\n",
    "    def calculate_answer(self, question):\n",
    "        question_list = question.split(\" \")\n",
    "        tag_list = self.nlp_operator.get_ner(\n",
    "            question\n",
    "        )  # returns e.g. [['O', 'O', 'O', 'O', 'O']]\n",
    "\n",
    "        print(\"tag_list: \", tag_list)\n",
    "        wh_word = question_list[0].upper()\n",
    "        if wh_word == \"WHEN\":\n",
    "            return self.calculate_when_answer(\n",
    "                copy.deepcopy(question), tag_list[0]\n",
    "            )  # this is supposed to be tag_list, right?\n",
    "        else:\n",
    "            return self.calculate_other_answer(copy.deepcopy(question), tag_list[0])\n",
    "\n",
    "    # this is also not a question_list but a question\n",
    "    def calculate_other_answer(self, question, tag_list):\n",
    "        print(\"calculate other answer\")\n",
    "        question_list = question.split(\" \")\n",
    "        print(tag_list)\n",
    "        try:\n",
    "            # find entity\n",
    "            indexes = [index for index, val in enumerate(tag_list) if val != \"O\"]\n",
    "            print(indexes)\n",
    "            entity = (\n",
    "                \" \".join(question_list[indexes[0] : indexes[-1] + 1])\n",
    "                .rstrip(\"?\")\n",
    "            )\n",
    "            print(entity)\n",
    "\n",
    "            relations = self.nlp_operator.get_relation(question)\n",
    "            print(relations)\n",
    "            assert len(relations) == 1\n",
    "            relations = relations[0]\n",
    "\n",
    "            possible_answer = self.search_answer(entity, relations, 0)\n",
    "\n",
    "        except:\n",
    "            temp = copy.deepcopy(question_list)\n",
    "            possible_answer = self.forcely_search(temp, 0)\n",
    "\n",
    "        finally:\n",
    "            return possible_answer\n",
    "\n",
    "    # you are not passing the question list, but question?\n",
    "    def calculate_when_answer(self, question_list, tag_list):\n",
    "        try:\n",
    "            # find entity\n",
    "            indexes = [index for index, val in enumerate(tag_list) if val != \"O\"]\n",
    "            entity = (\n",
    "                \" \".join(question_list[indexes[0] : indexes[-1] + 1])\n",
    "                .rstrip(\"?\")\n",
    "                .rstrip('\"')\n",
    "                .rstrip(\"'\")\n",
    "            )\n",
    "\n",
    "            entity_list = \" \".join(question_list[indexes[0] : indexes[-1] + 1]).split(\n",
    "                \" \"\n",
    "            )\n",
    "\n",
    "            # delete entity word\n",
    "            temp = copy.deepcopy(question_list)\n",
    "            for word in entity_list:\n",
    "                temp.remove(word)\n",
    "\n",
    "            for word in self.all_delete_words:\n",
    "                try:\n",
    "                    temp.remove(word)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            assert len(temp) == 1\n",
    "            relations = temp[0] + \" time\"\n",
    "\n",
    "            possible_answer = []\n",
    "            possible_answer = self.search_answer(entity, relations, 1)\n",
    "\n",
    "        except:\n",
    "            temp = copy.deepcopy(question_list)\n",
    "            possible_answer = self.forcely_search(temp, 1)\n",
    "\n",
    "        return possible_answer\n",
    "\n",
    "    def search_answer(self, entity_word, related_word, is_when):\n",
    "        search_loop = 0\n",
    "        search_flag = 0\n",
    "        edit_distance = 1\n",
    "\n",
    "        node_distance_dict = self.calculate_node_distance(entity_word)\n",
    "        pred_distance_dict = self.calculate_pred_distance(related_word)\n",
    "\n",
    "        searched_answers = []\n",
    "        for n_key in node_distance_dict.keys():\n",
    "            search_loop += 1\n",
    "\n",
    "            if node_distance_dict[n_key] == 0:\n",
    "                edit_distance = 0\n",
    "            else:\n",
    "                edit_distance = 1\n",
    "\n",
    "            for p_key in pred_distance_dict.keys():                \n",
    "                if is_when:\n",
    "                    query = f'''\n",
    "                        PREFIX ddis: <http://ddis.ch/atai/>\n",
    "                        PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "                        PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "                        PREFIX schema: <http://schema.org/>\n",
    "                        SELECT ?date WHERE{{    \n",
    "                            wd:{n_key} wdt:{p_key} ?date.\n",
    "                        }}\n",
    "                        LIMIT 1\n",
    "                        '''\n",
    "                else:\n",
    "                    query = f'''\n",
    "                        PREFIX ddis: <http://ddis.ch/atai/>\n",
    "                        PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "                        PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "                        PREFIX schema: <http://schema.org/>\n",
    "                        SELECT ?entity_name WHERE{{    \n",
    "                            wd:{n_key} wdt:{p_key} ?temp.\n",
    "                            ?temp rdfs:label ?entity_name.\n",
    "                        }}\n",
    "                        LIMIT 1\n",
    "                    '''\n",
    "\n",
    "                print(query)\n",
    "\n",
    "                answers = graph_operator.query(query)\n",
    "                print(answers)\n",
    "                if len(answers) > 0:\n",
    "                    search_flag = 1\n",
    "                if search_flag == 1:\n",
    "                    searched_answers.append(answers)\n",
    "                    break\n",
    "            if search_flag == 1 and edit_distance == 1:\n",
    "                break\n",
    "            if search_loop > 10:\n",
    "                answers = []\n",
    "                break\n",
    "\n",
    "        return searched_answers\n",
    "\n",
    "    def search_answer_for_all_O(self, entity_word, related_word, is_when):\n",
    "        node_distance_dict = self.calculate_node_distance(entity_word)\n",
    "        pred_distance_dict = self.calculate_pred_distance(related_word)\n",
    "\n",
    "        search_flag = 0\n",
    "\n",
    "        # entity distance seems reliable, try 5 times\n",
    "        try_times = 0\n",
    "        for n_key in node_distance_dict.keys():\n",
    "            try_times += 1\n",
    "            for p_key in pred_distance_dict.keys():\n",
    "                if is_when:\n",
    "                    query = f'''\n",
    "                        PREFIX ddis: <http://ddis.ch/atai/>\n",
    "                        PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "                        PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "                        PREFIX schema: <http://schema.org/>\n",
    "                        SELECT ?date WHERE{{    \n",
    "                            wd:{n_key} wdt:{p_key} ?date.\n",
    "                        }}\n",
    "                        LIMIT 1\n",
    "                        '''\n",
    "                else:\n",
    "                    query = f'''\n",
    "                        PREFIX ddis: <http://ddis.ch/atai/>\n",
    "                        PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "                        PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "                        PREFIX schema: <http://schema.org/>\n",
    "                        SELECT ?entity_name WHERE{{    \n",
    "                            wd:{n_key} wdt:{p_key} ?temp.\n",
    "                            ?temp rdfs:label ?entity_name.\n",
    "                        }}\n",
    "                        LIMIT 1\n",
    "                    '''\n",
    "\n",
    "                answers = [str(s) for s, in g.query(query)]\n",
    "                if len(answers) > 0 and len(answers[0]) == 10:\n",
    "                    search_flag = 1\n",
    "                if search_flag == 1:\n",
    "                    break\n",
    "            if search_flag == 1:\n",
    "                break\n",
    "            if try_times > 10:\n",
    "                break\n",
    "        return answers\n",
    "\n",
    "    def calculate_node_distance(self, word):\n",
    "        distance_dict = {}\n",
    "        print(\"entity matching for {}\".format(word))\n",
    "        for key, value in self.nodes.items():\n",
    "            distance_dict[key.split(\"/\")[-1]] = editdistance.eval(value, word)\n",
    "        distance_dict = dict(sorted(distance_dict.items(), key=lambda x: x[1]))\n",
    "        return distance_dict\n",
    "\n",
    "    def calculate_pred_distance(self, related_word):\n",
    "        pred_distance_dict = {}\n",
    "        print(\"relation matching for {}\".format(related_word))\n",
    "        for key, value in self.predicates.items():\n",
    "            pred_distance_dict[key.split(\"/\")[-1]] = editdistance.eval(\n",
    "                value, related_word\n",
    "            )\n",
    "        pred_distance_dict = dict(\n",
    "            sorted(pred_distance_dict.items(), key=lambda x: x[1])\n",
    "        )\n",
    "\n",
    "        # don't comment this block\n",
    "        try:\n",
    "            del pred_distance_dict[\"rdf-schema#label\"]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        return pred_distance_dict\n",
    "\n",
    "    def forcely_search(self, question_list, is_when):\n",
    "        for word in self.all_delete_words:\n",
    "            try:\n",
    "                question_list.remove(word)\n",
    "            except:\n",
    "                pass\n",
    "        possible_word = copy.deepcopy(question_list)\n",
    "        for i in range(len(possible_word)):\n",
    "            possible_word[i] = (\n",
    "                possible_word[i].replace(\"?\", \"\").replace('\"', \"\").replace(\"'\", \"\")\n",
    "            )\n",
    "\n",
    "        possible_relation_word_first = possible_word[0]\n",
    "        possible_entity_word_first = \" \".join(possible_word[1:])\n",
    "        possible_relation_word_last = possible_word[-1]\n",
    "        possible_entity_word_last = \" \".join(possible_word[0:-1])\n",
    "\n",
    "        if is_when == 1:\n",
    "            possible_relation_word_first += \" time\"\n",
    "            possible_relation_word_last += +\" time\"\n",
    "\n",
    "        possible_answer_list1 = self.search_answer_for_all_O(\n",
    "            possible_entity_word_first, possible_relation_word_first\n",
    "        )\n",
    "        possible_answer_list2 = self.search_answer_for_all_O(\n",
    "            possible_entity_word_last, possible_relation_word_last\n",
    "        )\n",
    "\n",
    "        possible_answer = []\n",
    "        if len(possible_answer_list1) != 0:\n",
    "            possible_answer = possible_answer_list1\n",
    "        if len(possible_answer_list2) != 0:\n",
    "            possible_answer = possible_answer_list2\n",
    "\n",
    "        return possible_answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading graph ...\n",
      "loaded graph successfully!\n"
     ]
    }
   ],
   "source": [
    "graph_operator = GraphOperations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate other answer\n",
      "[['O', 'O', 'O', 'O', 'O', 'B-org', 'B-per', 'I-per', 'I-per', 'I-per', 'I-per', 'O', 'O', 'B-org']]\n",
      "[0]\n",
      "Who\n",
      "['director']\n",
      "entity matching for Who\n",
      "relation matching for director\n",
      "\n",
      "                        PREFIX ddis: <http://ddis.ch/atai/>\n",
      "                        PREFIX wd: <http://www.wikidata.org/entity/>\n",
      "                        PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
      "                        PREFIX schema: <http://schema.org/>\n",
      "                        SELECT ?entity_name WHERE{    \n",
      "                            wd:Q58880906 wdt:P57 ?temp.\n",
      "                            ?temp rdfs:label ?entity_name.\n",
      "                        }\n",
      "                        LIMIT 1\n",
      "                    \n",
      "message in sparql\n",
      "\n",
      "                        PREFIX ddis: <http://ddis.ch/atai/>\n",
      "                        PREFIX wd: <http://www.wikidata.org/entity/>\n",
      "                        PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
      "                        PREFIX schema: <http://schema.org/>\n",
      "                        SELECT ?entity_name WHERE{    \n",
      "                            wd:Q58880906 wdt:P57 ?temp.\n",
      "                            ?temp rdfs:label ?entity_name.\n",
      "                        }\n",
      "                        LIMIT 1\n",
      "                    \n",
      "[]\n",
      "[]\n",
      "\n",
      "                        PREFIX ddis: <http://ddis.ch/atai/>\n",
      "                        PREFIX wd: <http://www.wikidata.org/entity/>\n",
      "                        PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
      "                        PREFIX schema: <http://schema.org/>\n",
      "                        SELECT ?entity_name WHERE{    \n",
      "                            wd:Q58880906 wdt:P170 ?temp.\n",
      "                            ?temp rdfs:label ?entity_name.\n",
      "                        }\n",
      "                        LIMIT 1\n",
      "                    \n",
      "message in sparql\n",
      "\n",
      "                        PREFIX ddis: <http://ddis.ch/atai/>\n",
      "                        PREFIX wd: <http://www.wikidata.org/entity/>\n",
      "                        PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
      "                        PREFIX schema: <http://schema.org/>\n",
      "                        SELECT ?entity_name WHERE{    \n",
      "                            wd:Q58880906 wdt:P170 ?temp.\n",
      "                            ?temp rdfs:label ?entity_name.\n",
      "                        }\n",
      "                        LIMIT 1\n",
      "                    \n",
      "['Dr. Seuss']\n",
      "['Dr. Seuss']\n",
      "\n",
      "                        PREFIX ddis: <http://ddis.ch/atai/>\n",
      "                        PREFIX wd: <http://www.wikidata.org/entity/>\n",
      "                        PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
      "                        PREFIX schema: <http://schema.org/>\n",
      "                        SELECT ?entity_name WHERE{    \n",
      "                            wd:Q1324276 wdt:P57 ?temp.\n",
      "                            ?temp rdfs:label ?entity_name.\n",
      "                        }\n",
      "                        LIMIT 1\n",
      "                    \n",
      "message in sparql\n",
      "\n",
      "                        PREFIX ddis: <http://ddis.ch/atai/>\n",
      "                        PREFIX wd: <http://www.wikidata.org/entity/>\n",
      "                        PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
      "                        PREFIX schema: <http://schema.org/>\n",
      "                        SELECT ?entity_name WHERE{    \n",
      "                            wd:Q1324276 wdt:P57 ?temp.\n",
      "                            ?temp rdfs:label ?entity_name.\n",
      "                        }\n",
      "                        LIMIT 1\n",
      "                    \n",
      "['Daisy von Scherler Mayer']\n",
      "['Daisy von Scherler Mayer']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Dr. Seuss'], ['Daisy von Scherler Mayer']]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculator = AnswerCalculator()\n",
    "answer = calculator.calculate_other_answer(\"Who is the director of Star Wars: Episode VI - Return of the Jedi?\", [['O', 'O', 'O', 'O', 'O', 'B-org', 'B-per', 'I-per', 'I-per', 'I-per', 'I-per', 'O', 'O', 'B-org']])\n",
    "\n",
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
